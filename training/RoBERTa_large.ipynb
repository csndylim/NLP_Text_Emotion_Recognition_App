{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RoBERTa_large.ipynb","provenance":[],"collapsed_sections":["OW9pCCPaQJa6","beCCkJ6DQBtf","0KgP7rRLQFZO","OuzN46oCQMOc","RJ9ZRe_4BGGf","L-pnKfdrjE1A","6DKbJsD9hXIC","ZQy1Ndvqf33J","yJR_LDAQNjaR","6sBbhhzJiENf","hpDp_VFKjI3_","5Gpk3QhujbD2","g4wUnrjUHsSq","uqUG7OGFgOOW","jUfUWS5-It4a","lW0sM4IRQX7a","LEmMcwr7UICq","UbJwWsZ7UKFL"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f208cb1f186b4359bb1c0964a5dd8ab5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_14b34624ff23482a8073776274d7672b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e2d6fae938cd41ba8f56e369a636d119","IPY_MODEL_fed6f477426143eba904e5ecbf3c7ef5","IPY_MODEL_592caa6a61cd4a5197ee7736d3c0dae7"]}},"14b34624ff23482a8073776274d7672b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2d6fae938cd41ba8f56e369a636d119":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_192f2f8f1432467ca42ec3e30ae08485","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff174a3dbc014df9aa7e1e13ec96c317"}},"fed6f477426143eba904e5ecbf3c7ef5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0b2f4d2713e2494e94a1042d64a63130","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_684ef40c110e4a94ae448caa197d66f4"}},"592caa6a61cd4a5197ee7736d3c0dae7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_da2e2268ead44ce69046c04a78e8589e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 878k/878k [00:01&lt;00:00, 1.19MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_259beefd8ce54dabbc9954eef94179ff"}},"192f2f8f1432467ca42ec3e30ae08485":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ff174a3dbc014df9aa7e1e13ec96c317":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b2f4d2713e2494e94a1042d64a63130":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"684ef40c110e4a94ae448caa197d66f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da2e2268ead44ce69046c04a78e8589e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"259beefd8ce54dabbc9954eef94179ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"effe9930ad4a4636b61b1b09a96c5ec7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9510e6968b5e4fe88d87a703600aa253","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_15d62bbe634d4dd8b2c43d58635cf776","IPY_MODEL_14b1add9d88c4a8a87e26d30bbf43649","IPY_MODEL_bc5ee6403be94a84be6aef0b207c673b"]}},"9510e6968b5e4fe88d87a703600aa253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15d62bbe634d4dd8b2c43d58635cf776":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_36cd10c285a94bd183f90a32a473929d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f394429ecc1342ffadb33064fe3f8f57"}},"14b1add9d88c4a8a87e26d30bbf43649":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0e418feeeaea4c6795a99a04ab099237","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13fc911f19014b96b01cfb6fb70897c4"}},"bc5ee6403be94a84be6aef0b207c673b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_49e14234fb2d4475b0b7a7051e7b5de2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 446k/446k [00:00&lt;00:00, 640kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_835da3737ba049039ac7681083c7f630"}},"36cd10c285a94bd183f90a32a473929d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f394429ecc1342ffadb33064fe3f8f57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e418feeeaea4c6795a99a04ab099237":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"13fc911f19014b96b01cfb6fb70897c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49e14234fb2d4475b0b7a7051e7b5de2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"835da3737ba049039ac7681083c7f630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"741fda1a8c5744d7961f886243ea8051":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_46d71416beff4184b72188f14ca5bd26","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14687ac5a31a4f38ac323363967f8ef8","IPY_MODEL_4694573e0ef743659d9f54cb28290f3d","IPY_MODEL_9566d521efcc46fc95e5d0c73241ba75"]}},"46d71416beff4184b72188f14ca5bd26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14687ac5a31a4f38ac323363967f8ef8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4c256508583b4b7a8a2237adf455305d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f462056f413b48838132d6f17896e36c"}},"4694573e0ef743659d9f54cb28290f3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_575854194b1d46af8341a26adbd62918","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5aa468ea58b04ed89bfb194a2924bf0a"}},"9566d521efcc46fc95e5d0c73241ba75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9d46a6af9e364dd0a68092ea6df61862","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.29M/1.29M [00:01&lt;00:00, 1.16MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b22f84bfbb84466845cb17c96675245"}},"4c256508583b4b7a8a2237adf455305d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f462056f413b48838132d6f17896e36c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"575854194b1d46af8341a26adbd62918":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5aa468ea58b04ed89bfb194a2924bf0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d46a6af9e364dd0a68092ea6df61862":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7b22f84bfbb84466845cb17c96675245":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1182bfe26d7c427d973f8f653b59fd59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b846443c0b142e1b542e534421445c2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_335370049d3544da8162be88655228f2","IPY_MODEL_bdc7205a7d0843128330dbde41860f23","IPY_MODEL_7af72824f4b7426296c8643d8e53d98a"]}},"3b846443c0b142e1b542e534421445c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"335370049d3544da8162be88655228f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_226ad7a6a1ad45e1bf9a81e4603e1c91","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0a075d1600b41c3a631777dac8fad22"}},"bdc7205a7d0843128330dbde41860f23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1a6fb39df7254472a0c43bc085cfb754","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b36980277b7a467f851be9a60d5e64e5"}},"7af72824f4b7426296c8643d8e53d98a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_12c800d6ee3f4ace8e944b2bdfe4641e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:00&lt;00:00, 17.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24a5aa7c69154ea281bdb7eb05e49e9d"}},"226ad7a6a1ad45e1bf9a81e4603e1c91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d0a075d1600b41c3a631777dac8fad22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a6fb39df7254472a0c43bc085cfb754":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b36980277b7a467f851be9a60d5e64e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12c800d6ee3f4ace8e944b2bdfe4641e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24a5aa7c69154ea281bdb7eb05e49e9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"862e535fccd341829fedafaa73494f51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5104eb46f9f34607bb0bd24630c952af","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9b30dc2a6c0547a984370079840f3712","IPY_MODEL_12e131e7bbc044079d3c25c0b65179d3","IPY_MODEL_b2e8aab980f9479a91c0f3fbcff7692b"]}},"5104eb46f9f34607bb0bd24630c952af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b30dc2a6c0547a984370079840f3712":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ffe147dc6b54a9782ebe2a978954e65","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a0123b82da0442da5a0fb53d610f708"}},"12e131e7bbc044079d3c25c0b65179d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e09e3f6cf90b4eb087ba19f0db56d5b6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9715e08dfd62456ca0534f878a52f35c"}},"b2e8aab980f9479a91c0f3fbcff7692b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4c214fe321c64803af02ad926794d6ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 478M/478M [00:10&lt;00:00, 53.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff2a4883a6294455bbdb0a58f5b18d01"}},"0ffe147dc6b54a9782ebe2a978954e65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2a0123b82da0442da5a0fb53d610f708":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e09e3f6cf90b4eb087ba19f0db56d5b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9715e08dfd62456ca0534f878a52f35c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c214fe321c64803af02ad926794d6ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ff2a4883a6294455bbdb0a58f5b18d01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89050e08f97548ca92e2cf50070124c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_739e974f42e5477c80ed0fa42eb4de67","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_81ddfdadade34586b1abcd11c1934a2b","IPY_MODEL_bf84635dccb74a37bf77ec758da3d664","IPY_MODEL_0f3dcb26bbb444a1aa8f0f53a44594de"]}},"739e974f42e5477c80ed0fa42eb4de67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81ddfdadade34586b1abcd11c1934a2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_af8e2d688e5e464bb76c40eddfcc9b58","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d9f58131517d440f889fe840394ef698"}},"bf84635dccb74a37bf77ec758da3d664":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7c4bd096c4a34a569091991b17bd9058","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_40ef966a81a345c28828e5da83882f3d"}},"0f3dcb26bbb444a1aa8f0f53a44594de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fdb3ecac5c264e6f8734ad82636c85a7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 878k/878k [00:00&lt;00:00, 888kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ecbd1270cf45493d9ace9c71b6946cfd"}},"af8e2d688e5e464bb76c40eddfcc9b58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d9f58131517d440f889fe840394ef698":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c4bd096c4a34a569091991b17bd9058":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"40ef966a81a345c28828e5da83882f3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fdb3ecac5c264e6f8734ad82636c85a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ecbd1270cf45493d9ace9c71b6946cfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c67a860a331149b6bb926de2c99e29e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_75e1c6fcce1643dea06a04792bf47f7c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7141a00ba3c849b4a8dc872615c5028b","IPY_MODEL_4bad9c8552c44168b2ca85783dbf9886","IPY_MODEL_e535c593c82d4c6386f95c9bfb48a9d2"]}},"75e1c6fcce1643dea06a04792bf47f7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7141a00ba3c849b4a8dc872615c5028b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b6fce4f2dfee4413866361757a99bae7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b23fcd3e0984e84baf3494ce94b8a8f"}},"4bad9c8552c44168b2ca85783dbf9886":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9a7b694d6df24a678fa911dbf9d235f7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b520d4274b5846ee9976f6c372fc22b2"}},"e535c593c82d4c6386f95c9bfb48a9d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_837537c758364c7eb7c790861d9f0f3c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 446k/446k [00:00&lt;00:00, 1.34MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1ec16b9f9d0429f943c6cc9e79af549"}},"b6fce4f2dfee4413866361757a99bae7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1b23fcd3e0984e84baf3494ce94b8a8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a7b694d6df24a678fa911dbf9d235f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b520d4274b5846ee9976f6c372fc22b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"837537c758364c7eb7c790861d9f0f3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1ec16b9f9d0429f943c6cc9e79af549":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1d6feb1ed3c14a20a430f756b4a3f37a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2dc2c893fa2c48afbff10f2e11d929e5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d416d7de63224a50b42c962aee8a3aa8","IPY_MODEL_71e868e075f741f582c5837bf67eb49e","IPY_MODEL_0cd7630d46c545a893ba47f27f72a7ab"]}},"2dc2c893fa2c48afbff10f2e11d929e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d416d7de63224a50b42c962aee8a3aa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cdb383f1dd974ff28ad62bcc83b5553e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc5aae85cfff4933ae6572c75e34bf6f"}},"71e868e075f741f582c5837bf67eb49e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_af414677919e48b19bd24870cdd5b49d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89cb96f119d643d8a63af488867ee348"}},"0cd7630d46c545a893ba47f27f72a7ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eb2e0cb12bfe41a0b32b43ac928c5011","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.29M/1.29M [00:00&lt;00:00, 2.97MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d01ab7c03994841b2e71712d0f69edd"}},"cdb383f1dd974ff28ad62bcc83b5553e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bc5aae85cfff4933ae6572c75e34bf6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af414677919e48b19bd24870cdd5b49d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"89cb96f119d643d8a63af488867ee348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb2e0cb12bfe41a0b32b43ac928c5011":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6d01ab7c03994841b2e71712d0f69edd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae987be3f27e4469b557b5f6942fff49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d84498341952480e8847b36480015c56","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ad99b6cbbc96488ca45563428035b242","IPY_MODEL_1b693378bbc94a9f8257f157b86ee78c","IPY_MODEL_bdbb9876b4a14060b711d2adbdab60e5"]}},"d84498341952480e8847b36480015c56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad99b6cbbc96488ca45563428035b242":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1c4641518fe244acaff21897d75f599c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a9cc366669a47df9a56e048f81e7955"}},"1b693378bbc94a9f8257f157b86ee78c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cc38d94371e54be18422724b19d5c4bf","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6cda840614df46b6b73127629dcd742b"}},"bdbb9876b4a14060b711d2adbdab60e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d87a5dd5012f4ef29642804ee3eb5bb1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 482/482 [00:00&lt;00:00, 14.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c564ce2ef7f245c0985070eacab6053e"}},"1c4641518fe244acaff21897d75f599c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7a9cc366669a47df9a56e048f81e7955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc38d94371e54be18422724b19d5c4bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6cda840614df46b6b73127629dcd742b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d87a5dd5012f4ef29642804ee3eb5bb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c564ce2ef7f245c0985070eacab6053e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a590612e9b0489fb145ddb9bbc5b53e":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a5fb0539f5424dd4b3973637186b0a98","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c8733d81b80f46d8b03d871261ff9954","IPY_MODEL_2c0c4cc6db674c3595c343c70f2595f5"]}},"a5fb0539f5424dd4b3973637186b0a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8733d81b80f46d8b03d871261ff9954":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_50e9b3a2ce864e12b532a87d851234b6","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.38MB of 0.38MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c9751398fef463a83c4175eeb477eeb"}},"2c0c4cc6db674c3595c343c70f2595f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b536bccc209f47358ec2b0b46f57bd84","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73c01207070c4f788736b607982b604c"}},"50e9b3a2ce864e12b532a87d851234b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c9751398fef463a83c4175eeb477eeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b536bccc209f47358ec2b0b46f57bd84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"73c01207070c4f788736b607982b604c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"94bf6ce8f1e94989910b045a01318f5f":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a21f91fd51e94053bb3e440ccb5573fc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_812d3fc4c22545f08d2e79e3a2fc2661","IPY_MODEL_d37a4c1ca8784fb89666c725c755bfdf"]}},"a21f91fd51e94053bb3e440ccb5573fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"812d3fc4c22545f08d2e79e3a2fc2661":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_d16c9542efe74e8a91f6a1cd1cfcba64","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.80MB of 5.80MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd7eea8a76a04289a143f92e6793f8da"}},"d37a4c1ca8784fb89666c725c755bfdf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f27d89663a664abcbc5b75fd3be49e87","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_52cca71ff99c4d278e436e1f7fb31dff"}},"d16c9542efe74e8a91f6a1cd1cfcba64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd7eea8a76a04289a143f92e6793f8da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f27d89663a664abcbc5b75fd3be49e87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"52cca71ff99c4d278e436e1f7fb31dff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21ca3a292a6443d3847747d56b6b33d0":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4fcd5146d3a94e3fbe10b9c3f4d7f48b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_17b818ba71044ddfab44282ea8900a33","IPY_MODEL_1f1f9f1dbbf7499d90a5515f071f9e91"]}},"4fcd5146d3a94e3fbe10b9c3f4d7f48b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17b818ba71044ddfab44282ea8900a33":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_0115a66498e740fbb05a11a262a2c614","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.51MB of 5.51MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce58fc517511437fb66d07ecef7dd236"}},"1f1f9f1dbbf7499d90a5515f071f9e91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6c45efd946b142b88e29e6b77b15e9af","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0528b932d7da487e9dc45cd8acc4ae33"}},"0115a66498e740fbb05a11a262a2c614":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ce58fc517511437fb66d07ecef7dd236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c45efd946b142b88e29e6b77b15e9af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0528b932d7da487e9dc45cd8acc4ae33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd0464364ccc49809c40387b85ed30ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fc28f3fa07724fbab86046a01f8c158e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7c95bd7b0f1748ad81f169231d0dd4b5","IPY_MODEL_a38c15fab6e345ef9b16a28a2fb570ea","IPY_MODEL_402890aac5814202a26a17752f74ed74"]}},"fc28f3fa07724fbab86046a01f8c158e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c95bd7b0f1748ad81f169231d0dd4b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3653571f75484cd0b0d540e1406d4e77","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_037b307010564c51985fd4f03ce4f077"}},"a38c15fab6e345ef9b16a28a2fb570ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5874afd1dccf4112a80ed280a64bd833","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1425941629,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1425941629,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c7bfa66570354a369605ec4cedf184f5"}},"402890aac5814202a26a17752f74ed74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7a6dcfa8dede460ca3bb47a4e0d524b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.33G/1.33G [00:28&lt;00:00, 47.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d99c1ddedb014c128772f5d8658d7b28"}},"3653571f75484cd0b0d540e1406d4e77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"037b307010564c51985fd4f03ce4f077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5874afd1dccf4112a80ed280a64bd833":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c7bfa66570354a369605ec4cedf184f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a6dcfa8dede460ca3bb47a4e0d524b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d99c1ddedb014c128772f5d8658d7b28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1L-D4onRFZr","executionInfo":{"status":"ok","timestamp":1635593487335,"user_tz":-480,"elapsed":14440,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"eb1e2ac1-1e44-465d-82f2-3468d65c204e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"OW9pCCPaQJa6"},"source":["### Download dependencies"]},{"cell_type":"code","metadata":{"id":"wjcAMvXqtRSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635593494062,"user_tz":-480,"elapsed":6730,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"cd610ca2-2447-46a5-9a3a-e414d8d20220"},"source":["!pip install --upgrade transformers"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 56.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting huggingface-hub>=0.0.17\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 46.0 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 45.4 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.2\n"]}]},{"cell_type":"code","metadata":{"id":"ENUrJ4ywL9ti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635593500520,"user_tz":-480,"elapsed":6461,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"7a89e352-d3eb-4eba-862d-9be6cfb6031e"},"source":["!pip install pytorch-transformers"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 8.7 MB/s \n","\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.0.46)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.9.0+cu111)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 61.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n","Collecting boto3\n","  Downloading boto3-1.19.7-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 69.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.1 MB/s \n","\u001b[?25hCollecting botocore<1.23.0,>=1.22.7\n","  Downloading botocore-1.22.7-py3-none-any.whl (8.1 MB)\n","\u001b[K     |████████████████████████████████| 8.1 MB 35.7 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.7->boto3->pytorch-transformers) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 72.4 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.7->boto3->pytorch-transformers) (1.15.0)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 71.9 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.0.1)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, boto3, pytorch-transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.19.7 botocore-1.22.7 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sentencepiece-0.1.96 urllib3-1.25.11\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mITSXunyLVR1","executionInfo":{"status":"ok","timestamp":1635593514999,"user_tz":-480,"elapsed":14482,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"6bde1254-8f06-477f-bd15-08f034388ae3"},"source":["from transformers import __version__\n","print(__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["4.12.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNnZqTbH1Owv","executionInfo":{"status":"ok","timestamp":1635593517531,"user_tz":-480,"elapsed":2540,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"01ae3cf8-d524-402f-82e5-8c24de846b6b"},"source":["!pip install sentencepiece"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","metadata":{"id":"6MiGYWogQK7L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635593524320,"user_tz":-480,"elapsed":6793,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"e55b1847-f1b6-447a-b9b4-1677a0af0eb3"},"source":["!pip install wandb"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 9.9 MB/s \n","\u001b[?25hCollecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 73.5 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 74.9 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 8.9 MB/s \n","\u001b[?25hCollecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=3ff828027b1780c4213dc2c2e073feedbe8b8f7acf37f5f2134ec836fa70aa3a\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=f28ccc41e31c7377935d5ce9e5392486ef0abaf5ff6f655d4a13da75dcc34424\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"beCCkJ6DQBtf"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"GweU62UIQIqJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635593526136,"user_tz":-480,"elapsed":1824,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"75f1fe25-2608-448f-97ab-9b4fe11d7e98"},"source":["import pandas as pd\n","import numpy as np\n","import re\n","import regex\n","from tqdm import tqdm\n","\n","from sklearn import preprocessing, metrics\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n","from torch.utils.data import Dataset, DataLoader\n","\n","from tensorflow.keras.utils import to_categorical\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import tensorflow as tf\n","import transformers\n","from transformers import XLNetForSequenceClassification, XLNetTokenizer, TFXLNetModel, XLNetModel, AdamW, get_linear_schedule_with_warmup\n","from transformers import RobertaModel, RobertaTokenizer\n","\n","import nltk\n","from nltk.corpus import stopwords \n","from nltk.tokenize import WordPunctTokenizer\n","from string import punctuation\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('stopwords')\n","nltk.download('wordnet')"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cupnx6q_vNb2","executionInfo":{"status":"ok","timestamp":1635593526137,"user_tz":-480,"elapsed":7,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"57a8cc2b-0557-4479-d138-06c4c4a669b8"},"source":["print(torch.__version__)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["1.9.0+cu111\n"]}]},{"cell_type":"code","metadata":{"id":"tayL3He7uvF8","executionInfo":{"status":"ok","timestamp":1635593526632,"user_tz":-480,"elapsed":500,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_9qOO8LiN2p","executionInfo":{"status":"ok","timestamp":1635593526632,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0KgP7rRLQFZO"},"source":["### Load data"]},{"cell_type":"code","metadata":{"id":"AfutfGKBQAlH","executionInfo":{"status":"ok","timestamp":1635593526633,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["f_path = '/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/dataset/crowdflower_text_emotion.csv'"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgpvlBcMQAnH","executionInfo":{"status":"ok","timestamp":1635593528299,"user_tz":-480,"elapsed":854,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["df = pd.read_csv(f_path)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OuzN46oCQMOc"},"source":["### Data preprocessing and analysis"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"oGKcv1-GQApG","executionInfo":{"status":"ok","timestamp":1635593528299,"user_tz":-480,"elapsed":7,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"6944ff52-7bfe-4b4b-8070-9b4ef0d4d4c2"},"source":["df.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>sentiment</th>\n","      <th>author</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1956967341</td>\n","      <td>empty</td>\n","      <td>xoshayzers</td>\n","      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1956967666</td>\n","      <td>sadness</td>\n","      <td>wannamama</td>\n","      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1956967696</td>\n","      <td>sadness</td>\n","      <td>coolfunky</td>\n","      <td>Funeral ceremony...gloomy friday...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1956967789</td>\n","      <td>enthusiasm</td>\n","      <td>czareaquino</td>\n","      <td>wants to hang out with friends SOON!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1956968416</td>\n","      <td>neutral</td>\n","      <td>xkilljoyx</td>\n","      <td>@dannycastillo We want to trade with someone w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     tweet_id  ...                                            content\n","0  1956967341  ...  @tiffanylue i know  i was listenin to bad habi...\n","1  1956967666  ...  Layin n bed with a headache  ughhhh...waitin o...\n","2  1956967696  ...                Funeral ceremony...gloomy friday...\n","3  1956967789  ...               wants to hang out with friends SOON!\n","4  1956968416  ...  @dannycastillo We want to trade with someone w...\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3uI-NOsQArQ","executionInfo":{"status":"ok","timestamp":1635593528301,"user_tz":-480,"elapsed":7,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"a3355626-6506-43e3-adb0-ae016c17b81f"},"source":["# Check emotions labels\n","\n","labels = df.sentiment.unique()\n","print(labels)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["['empty' 'sadness' 'enthusiasm' 'neutral' 'worry' 'surprise' 'love' 'fun'\n"," 'hate' 'happiness' 'boredom' 'relief' 'anger']\n"]}]},{"cell_type":"code","metadata":{"id":"KG7DyxzPQAtI","executionInfo":{"status":"ok","timestamp":1635593528301,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["# # Remove 'empty' emotion\n","# labels = np.delete(labels, 0)\n","\n","# # Remove 'empty' rows\n","# df = df.drop(df[\"sentiment\"].loc[df[\"sentiment\"]=='empty'].index)\n","\n","# Remove irrelevant columns\n","df = df.drop(columns=['tweet_id', 'author'])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IA3PHfffNONe","executionInfo":{"status":"ok","timestamp":1635593528302,"user_tz":-480,"elapsed":7,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"0da2ec8e-12ce-443f-feac-25fe90ef891a"},"source":["# Check for null cells\n","df['sentiment'].isnull().values.any()\n"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"3bNZV9MPNOLf","executionInfo":{"status":"ok","timestamp":1635593528610,"user_tz":-480,"elapsed":315,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["# Text cleaning\n","# def clean(x):\n","#     #x = x.lower()\n","#     x = re.sub('[^\\w\\s]', ' ', x)\n","\n","#     return \"\".join(x)\n","\n","# df['content_cleaned'] = df.apply(lambda x: clean(x.content), axis=1)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"lw6l6A1i7vUk","executionInfo":{"status":"ok","timestamp":1635593530632,"user_tz":-480,"elapsed":2025,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["wordnet_lemmatizer = WordNetLemmatizer()\n","\n","stop = stopwords.words('english')\n","\n","for punct in punctuation:\n","    stop.append(punct)\n","\n","def clean(x, stop_words):\n","    word_tokens = WordPunctTokenizer().tokenize(x.lower())\n","    x = [regex.sub(u'\\p{^Latin}', u'', w) for w in word_tokens if w.isalpha() and len(w) > 2]\n","    return \" \".join(x)\n","\n","df[\"content_cleaned\"] = df.content.apply(lambda x : clean(x, stop)) "],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNrhUEtWNOPz","executionInfo":{"status":"ok","timestamp":1635593530633,"user_tz":-480,"elapsed":16,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["# Check len of each content\n","df['content_count'] = df['content_cleaned'].str.split(\" \").str.len()"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"xfnMGd1PNOSv","executionInfo":{"status":"ok","timestamp":1635593530633,"user_tz":-480,"elapsed":16,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"f1ab1c22-23b4-4bc5-aab7-d805a48023f9"},"source":["# Check if any of the sequences are longer than 512\n","df[df.content_count > 512]"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>content</th>\n","      <th>content_cleaned</th>\n","      <th>content_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [sentiment, content, content_cleaned, content_count]\n","Index: []"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"BKJ0zVzG_4Di","executionInfo":{"status":"ok","timestamp":1635593530633,"user_tz":-480,"elapsed":15,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"a55100f5-f19d-4d1f-a9a3-903445ae43c3"},"source":["df.head()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>content</th>\n","      <th>content_cleaned</th>\n","      <th>content_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>empty</td>\n","      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n","      <td>tiffanylue know was listenin bad habit earlier...</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sadness</td>\n","      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n","      <td>layin bed with headache ughhhh waitin your call</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sadness</td>\n","      <td>Funeral ceremony...gloomy friday...</td>\n","      <td>funeral ceremony gloomy friday</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>enthusiasm</td>\n","      <td>wants to hang out with friends SOON!</td>\n","      <td>wants hang out with friends soon</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>neutral</td>\n","      <td>@dannycastillo We want to trade with someone w...</td>\n","      <td>dannycastillo want trade with someone who has ...</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sentiment  ... content_count\n","0       empty  ...            12\n","1     sadness  ...             8\n","2     sadness  ...             4\n","3  enthusiasm  ...             6\n","4     neutral  ...            12\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"RJ9ZRe_4BGGf"},"source":["### Label encoding classes"]},{"cell_type":"code","metadata":{"id":"MdPWKgwWF_d-","executionInfo":{"status":"ok","timestamp":1635593530634,"user_tz":-480,"elapsed":15,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["labels_dict = dict(zip(labels, (x for x in range(len(labels)) )))\n","df['sentiment_val'] = df['sentiment'].map(labels_dict)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLvTvEDeAggz","executionInfo":{"status":"ok","timestamp":1635593530634,"user_tz":-480,"elapsed":14,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["df = df.drop(columns=['sentiment', 'content_count', 'content'])"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"phXezD-LAqab","executionInfo":{"status":"ok","timestamp":1635593530634,"user_tz":-480,"elapsed":14,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"113e3af0-c420-426a-f81d-bf8d596553aa"},"source":["df.head()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content_cleaned</th>\n","      <th>sentiment_val</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tiffanylue know was listenin bad habit earlier...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>layin bed with headache ughhhh waitin your call</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>funeral ceremony gloomy friday</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wants hang out with friends soon</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dannycastillo want trade with someone who has ...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     content_cleaned  sentiment_val\n","0  tiffanylue know was listenin bad habit earlier...              0\n","1    layin bed with headache ughhhh waitin your call              1\n","2                     funeral ceremony gloomy friday              1\n","3                   wants hang out with friends soon              2\n","4  dannycastillo want trade with someone who has ...              3"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"Iz3SZaTNYQQM"},"source":["### Prep data for training/validation"]},{"cell_type":"code","metadata":{"id":"-KuaiJhtENUQ","executionInfo":{"status":"ok","timestamp":1635593530635,"user_tz":-480,"elapsed":14,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["class SentimentData(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe.content_cleaned\n","        self.targets = self.data.sentiment_val\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4xJ5o_xiXM1","executionInfo":{"status":"ok","timestamp":1635593530635,"user_tz":-480,"elapsed":13,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["# Batch Size\n","TRAIN_BATCH_SIZE = 12\n","VALID_BATCH_SIZE = 8"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"YULG6eb_KjTz","executionInfo":{"status":"ok","timestamp":1635593530635,"user_tz":-480,"elapsed":13,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 2\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 2\n","                }"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L-pnKfdrjE1A"},"source":["### RoBERTa models"]},{"cell_type":"markdown","metadata":{"id":"6DKbJsD9hXIC"},"source":["#### Base model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["f208cb1f186b4359bb1c0964a5dd8ab5","14b34624ff23482a8073776274d7672b","e2d6fae938cd41ba8f56e369a636d119","fed6f477426143eba904e5ecbf3c7ef5","592caa6a61cd4a5197ee7736d3c0dae7","192f2f8f1432467ca42ec3e30ae08485","ff174a3dbc014df9aa7e1e13ec96c317","0b2f4d2713e2494e94a1042d64a63130","684ef40c110e4a94ae448caa197d66f4","da2e2268ead44ce69046c04a78e8589e","259beefd8ce54dabbc9954eef94179ff","effe9930ad4a4636b61b1b09a96c5ec7","9510e6968b5e4fe88d87a703600aa253","15d62bbe634d4dd8b2c43d58635cf776","14b1add9d88c4a8a87e26d30bbf43649","bc5ee6403be94a84be6aef0b207c673b","36cd10c285a94bd183f90a32a473929d","f394429ecc1342ffadb33064fe3f8f57","0e418feeeaea4c6795a99a04ab099237","13fc911f19014b96b01cfb6fb70897c4","49e14234fb2d4475b0b7a7051e7b5de2","835da3737ba049039ac7681083c7f630","741fda1a8c5744d7961f886243ea8051","46d71416beff4184b72188f14ca5bd26","14687ac5a31a4f38ac323363967f8ef8","4694573e0ef743659d9f54cb28290f3d","9566d521efcc46fc95e5d0c73241ba75","4c256508583b4b7a8a2237adf455305d","f462056f413b48838132d6f17896e36c","575854194b1d46af8341a26adbd62918","5aa468ea58b04ed89bfb194a2924bf0a","9d46a6af9e364dd0a68092ea6df61862","7b22f84bfbb84466845cb17c96675245","1182bfe26d7c427d973f8f653b59fd59","3b846443c0b142e1b542e534421445c2","335370049d3544da8162be88655228f2","bdc7205a7d0843128330dbde41860f23","7af72824f4b7426296c8643d8e53d98a","226ad7a6a1ad45e1bf9a81e4603e1c91","d0a075d1600b41c3a631777dac8fad22","1a6fb39df7254472a0c43bc085cfb754","b36980277b7a467f851be9a60d5e64e5","12c800d6ee3f4ace8e944b2bdfe4641e","24a5aa7c69154ea281bdb7eb05e49e9d"]},"id":"KC5X1knahvyw","executionInfo":{"status":"ok","timestamp":1634815282974,"user_tz":-480,"elapsed":10761,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"}},"outputId":"ce2d61e3-a701-4063-efad-f6c0a00c87e7"},"source":["# Initialize tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f208cb1f186b4359bb1c0964a5dd8ab5","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"effe9930ad4a4636b61b1b09a96c5ec7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"741fda1a8c5744d7961f886243ea8051","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1182bfe26d7c427d973f8f653b59fd59","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"28ao1VRyjEQw"},"source":["class RobertaClass(torch.nn.Module):\n","    def __init__(self):\n","        super(RobertaClass, self).__init__()\n","        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, 13)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["862e535fccd341829fedafaa73494f51","5104eb46f9f34607bb0bd24630c952af","9b30dc2a6c0547a984370079840f3712","12e131e7bbc044079d3c25c0b65179d3","b2e8aab980f9479a91c0f3fbcff7692b","0ffe147dc6b54a9782ebe2a978954e65","2a0123b82da0442da5a0fb53d610f708","e09e3f6cf90b4eb087ba19f0db56d5b6","9715e08dfd62456ca0534f878a52f35c","4c214fe321c64803af02ad926794d6ba","ff2a4883a6294455bbdb0a58f5b18d01"]},"id":"Un7FvN-UiJ43","executionInfo":{"status":"ok","timestamp":1634815314873,"user_tz":-480,"elapsed":31913,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"}},"outputId":"24efdf06-fbde-4478-fb90-3d1935ae6835"},"source":[""],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"862e535fccd341829fedafaa73494f51","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaClass(\n","  (l1): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",")"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"ZQy1Ndvqf33J"},"source":["#### Large model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["89050e08f97548ca92e2cf50070124c7","739e974f42e5477c80ed0fa42eb4de67","81ddfdadade34586b1abcd11c1934a2b","bf84635dccb74a37bf77ec758da3d664","0f3dcb26bbb444a1aa8f0f53a44594de","af8e2d688e5e464bb76c40eddfcc9b58","d9f58131517d440f889fe840394ef698","7c4bd096c4a34a569091991b17bd9058","40ef966a81a345c28828e5da83882f3d","fdb3ecac5c264e6f8734ad82636c85a7","ecbd1270cf45493d9ace9c71b6946cfd","c67a860a331149b6bb926de2c99e29e3","75e1c6fcce1643dea06a04792bf47f7c","7141a00ba3c849b4a8dc872615c5028b","4bad9c8552c44168b2ca85783dbf9886","e535c593c82d4c6386f95c9bfb48a9d2","b6fce4f2dfee4413866361757a99bae7","1b23fcd3e0984e84baf3494ce94b8a8f","9a7b694d6df24a678fa911dbf9d235f7","b520d4274b5846ee9976f6c372fc22b2","837537c758364c7eb7c790861d9f0f3c","d1ec16b9f9d0429f943c6cc9e79af549","1d6feb1ed3c14a20a430f756b4a3f37a","2dc2c893fa2c48afbff10f2e11d929e5","d416d7de63224a50b42c962aee8a3aa8","71e868e075f741f582c5837bf67eb49e","0cd7630d46c545a893ba47f27f72a7ab","cdb383f1dd974ff28ad62bcc83b5553e","bc5aae85cfff4933ae6572c75e34bf6f","af414677919e48b19bd24870cdd5b49d","89cb96f119d643d8a63af488867ee348","eb2e0cb12bfe41a0b32b43ac928c5011","6d01ab7c03994841b2e71712d0f69edd","ae987be3f27e4469b557b5f6942fff49","d84498341952480e8847b36480015c56","ad99b6cbbc96488ca45563428035b242","1b693378bbc94a9f8257f157b86ee78c","bdbb9876b4a14060b711d2adbdab60e5","1c4641518fe244acaff21897d75f599c","7a9cc366669a47df9a56e048f81e7955","cc38d94371e54be18422724b19d5c4bf","6cda840614df46b6b73127629dcd742b","d87a5dd5012f4ef29642804ee3eb5bb1","c564ce2ef7f245c0985070eacab6053e"]},"id":"0UJ68aBIh6Ks","executionInfo":{"status":"ok","timestamp":1635593535272,"user_tz":-480,"elapsed":4650,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"624140b9-89ef-48cb-ed3a-a2b8ffabd24a"},"source":["# Initialize tokenizer\n","tokenizer2 = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89050e08f97548ca92e2cf50070124c7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c67a860a331149b6bb926de2c99e29e3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d6feb1ed3c14a20a430f756b4a3f37a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae987be3f27e4469b557b5f6942fff49","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"-afOea-Df33J","executionInfo":{"status":"ok","timestamp":1635593535272,"user_tz":-480,"elapsed":10,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["class RobertaClass(torch.nn.Module):\n","    def __init__(self):\n","        super(RobertaClass, self).__init__()\n","        self.l1 = RobertaModel.from_pretrained(\"roberta-large\")\n","        self.pre_classifier = torch.nn.Linear(1024, 1024)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(1024, 13)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yJR_LDAQNjaR"},"source":["### Train/Eval functions"]},{"cell_type":"markdown","metadata":{"id":"6sBbhhzJiENf"},"source":["#### Parameters"]},{"cell_type":"code","metadata":{"id":"KkXQL8QDiDwh","executionInfo":{"status":"ok","timestamp":1635593535272,"user_tz":-480,"elapsed":9,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["LEARNING_RATE = 1e-05\n","MAX_LEN = 256\n","\n","# Multi class loss\n","loss_function = torch.nn.CrossEntropyLoss()\n","\n","# Accuracy function\n","def calcuate_accuracy(preds, targets):\n","    n_correct = (preds==targets).sum().item()\n","    return n_correct"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hpDp_VFKjI3_"},"source":["#### Training"]},{"cell_type":"code","metadata":{"id":"fWl0UERQi_3C","executionInfo":{"status":"ok","timestamp":1635593535273,"user_tz":-480,"elapsed":10,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["# For RoBERTa base\n","def train(model, epoch, training_loader):\n","\n","  tr_loss = 0\n","  n_correct = 0\n","  nb_tr_steps = 0\n","  nb_tr_examples = 0\n","\n","  # Tell wandb to watch this model train\n","  wandb.watch(model)\n","\n","  model.train()\n","\n","  for _, data in tqdm(enumerate(training_loader, 0)):\n","\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.long)\n","\n","    outputs = model(ids, mask, token_type_ids)\n","    loss = loss_function(outputs, targets)\n","    tr_loss += loss.item()\n","    big_val, big_idx = torch.max(outputs.data, dim=1)\n","    n_correct += calcuate_accuracy(big_idx, targets)\n","\n","    nb_tr_steps += 1\n","    nb_tr_examples+=targets.size(0)\n","    \n","    if _%5000==0:\n","        loss_step = tr_loss/nb_tr_steps\n","        accu_step = (n_correct*100)/nb_tr_examples \n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    # Optimizer \n","    optimizer.step()\n","\n","  print('\\n')\n","  epoch_loss = tr_loss/nb_tr_steps\n","  epoch_accu = (n_correct*100)/nb_tr_examples\n","  print(f\"Training Loss Epoch {epoch+1}: {epoch_loss}\")\n","  print(f\"Training Accuracy Epoch {epoch+1}: {epoch_accu} \\n\")\n","  \n","  return epoch_accu, epoch_loss"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Gpk3QhujbD2"},"source":["#### Eval"]},{"cell_type":"code","metadata":{"id":"mGGf2WT9jKyS","executionInfo":{"status":"ok","timestamp":1635593535273,"user_tz":-480,"elapsed":9,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["def valid(model, testing_loader):\n","\n","    n_correct = 0; \n","    n_wrong = 0; \n","    total = 0; \n","    tr_loss=0; \n","    nb_tr_steps=0; \n","    nb_tr_examples=0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for _, data in tqdm(enumerate(testing_loader, 0)):\n","\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","            targets = data['targets'].to(device, dtype = torch.long)\n","            outputs = model(ids, mask, token_type_ids).squeeze()\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calcuate_accuracy(big_idx, targets)\n","\n","            nb_tr_steps += 1\n","            nb_tr_examples+=targets.size(0)\n","            \n","            if _%5000==0:\n","                loss_step = tr_loss/nb_tr_steps\n","                accu_step = (n_correct*100)/nb_tr_examples\n","        # Reduce LR on val loss plateau\n","        scheduler.step(loss)\n","\n","    print('\\n')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Validation Loss Epoch : {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","    \n","    return epoch_accu, epoch_loss\n"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g4wUnrjUHsSq"},"source":["### K-Fold (RoBERTa base)"]},{"cell_type":"code","metadata":{"id":"UYqaYA4fjK0R"},"source":["# Set K-fold\n","kf = KFold(n_splits=3, shuffle=True, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MqVdGDcavQpa","executionInfo":{"status":"ok","timestamp":1634702649643,"user_tz":-480,"elapsed":2873,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"}},"outputId":"73ce154b-8c7e-4eeb-db4d-55f93788f39d"},"source":["# Setup wandb for logging\n","import wandb\n","\n","wandb.login()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["3a590612e9b0489fb145ddb9bbc5b53e","a5fb0539f5424dd4b3973637186b0a98","c8733d81b80f46d8b03d871261ff9954","2c0c4cc6db674c3595c343c70f2595f5","50e9b3a2ce864e12b532a87d851234b6","3c9751398fef463a83c4175eeb477eeb","b536bccc209f47358ec2b0b46f57bd84","73c01207070c4f788736b607982b604c","94bf6ce8f1e94989910b045a01318f5f","a21f91fd51e94053bb3e440ccb5573fc","812d3fc4c22545f08d2e79e3a2fc2661","d37a4c1ca8784fb89666c725c755bfdf","d16c9542efe74e8a91f6a1cd1cfcba64","bd7eea8a76a04289a143f92e6793f8da","f27d89663a664abcbc5b75fd3be49e87","52cca71ff99c4d278e436e1f7fb31dff","21ca3a292a6443d3847747d56b6b33d0","4fcd5146d3a94e3fbe10b9c3f4d7f48b","17b818ba71044ddfab44282ea8900a33","1f1f9f1dbbf7499d90a5515f071f9e91","0115a66498e740fbb05a11a262a2c614","ce58fc517511437fb66d07ecef7dd236","6c45efd946b142b88e29e6b77b15e9af","0528b932d7da487e9dc45cd8acc4ae33"]},"id":"KEfTFkBEGv6J","executionInfo":{"status":"ok","timestamp":1634740032728,"user_tz":-480,"elapsed":36500964,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"}},"outputId":"7ece2284-c383-4556-e3cc-d436dd00e5f5"},"source":["EPOCHS=15\n","f = 1\n","df = df.reset_index(drop=True)\n","\n","for train_index, val_index in kf.split(df):\n","\n","  # Init model\n","  model = RobertaClass()\n","  model.to(device)\n","\n","  # Init wandb for logging\n","  wandb.init(project=\"Text_Emotion_Recognition_RoBERTa\", name=f\"3-Fold\")\n","\n","  train2 = df.iloc[train_index]\n","  test2 = df.iloc[val_index]\n","\n","  train2 = train2.reset_index(drop=True)\n","  test2 = df.drop(train2.index).reset_index(drop=True)\n","\n","  training_set = SentimentData(train2, tokenizer, MAX_LEN)\n","  testing_set = SentimentData(test2, tokenizer, MAX_LEN)\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","\n","  print(f\"Training fold {f}...\")\n","\n","  for epoch in range(0, EPOCHS):\n","    \n","    # Train\n","    train_acc, train_loss = train(model, epoch, training_loader)\n","    # Val\n","    val_acc, val_loss = valid(model, testing_loader)\n","    print(f\"Epoch {epoch+1} done!\")\n","    # Log metrics\n","    wandb.log({\"Train_Loss\": train_loss, \"Val_Loss\": val_loss, \"Train_Acc\": train_acc, \"Val_Acc\": val_acc, \"Epoch\": epoch})   \n","\n","  f+=1"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["Finishing last run (ID:1p9cx5l6) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 667... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a590612e9b0489fb145ddb9bbc5b53e","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","</div><div class=\"wandb-col\">\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">3-Fold</strong>: <a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/1p9cx5l6\" target=\"_blank\">https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/1p9cx5l6</a><br/>\n","Find logs at: <code>./wandb/run-20211020_040408-1p9cx5l6/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Successfully finished last run (ID:1p9cx5l6). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/3um7j2gy\" target=\"_blank\">3-Fold</a></strong> to <a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training fold 1...\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:18,  2.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 1: 1.7716083793348372\n","Training Accuracy Epoch 1: 40.002250056251405 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.7137293289605375\n","Validation Accuracy Epoch: 43.89530523473827\n","Epoch 0 done!\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:18,  2.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 2: 1.6706655806742818\n","Training Accuracy Epoch 2: 43.38483462086552 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.28it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.6297988302701956\n","Validation Accuracy Epoch: 46.53517324133794\n","Epoch 1 done!\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:18,  2.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 3: 1.5416250101234217\n","Training Accuracy Epoch 3: 47.85494637365934 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.30it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.5076111452899676\n","Validation Accuracy Epoch: 51.37243137843108\n","Epoch 2 done!\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:19,  2.45it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 4: 1.3937761763576697\n","Training Accuracy Epoch 4: 53.206330158253955 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.4326824261416062\n","Validation Accuracy Epoch: 55.152242387880605\n","Epoch 3 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:19,  2.45it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 5: 1.2256902600021224\n","Training Accuracy Epoch 5: 59.53273831845796 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.305486062840878\n","Validation Accuracy Epoch: 61.37693115344233\n","Epoch 4 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:21,  2.45it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 6: 1.0610851021355043\n","Training Accuracy Epoch 6: 65.19162979074477 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.2915328110186317\n","Validation Accuracy Epoch: 62.329383530823456\n","Epoch 5 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:22,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 7: 0.897652152087707\n","Training Accuracy Epoch 7: 70.90677266931674 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.19553070602943\n","Validation Accuracy Epoch: 67.45912704364781\n","Epoch 6 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:22,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 8: 0.7526130470048902\n","Training Accuracy Epoch 8: 75.52313807845196 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.1703552014464669\n","Validation Accuracy Epoch: 69.75401229938502\n","Epoch 7 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:22,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 9: 0.6239924557422118\n","Training Accuracy Epoch 9: 79.75324383109577 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.2428398652792834\n","Validation Accuracy Epoch: 69.91150442477876\n","Epoch 8 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:23,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 10: 0.5317488413328673\n","Training Accuracy Epoch 10: 82.68581714542863 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.1977815463317099\n","Validation Accuracy Epoch: 72.92635368231588\n","Epoch 9 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:24,  2.43it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 11: 0.43792906229456313\n","Training Accuracy Epoch 11: 85.61089027225681 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.1976127614014798\n","Validation Accuracy Epoch: 74.13379331033448\n","Epoch 10 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:25,  2.43it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 12: 0.3740375117394888\n","Training Accuracy Epoch 12: 87.77469436735919 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.2371575959245686\n","Validation Accuracy Epoch: 74.13379331033448\n","Epoch 11 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:26,  2.43it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 13: 0.32046836482871593\n","Training Accuracy Epoch 13: 89.64599114977874 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.267960470223384\n","Validation Accuracy Epoch: 75.02624868756563\n","Epoch 12 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:26,  2.43it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 14: 0.283573803081818\n","Training Accuracy Epoch 14: 90.75226880672017 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.2837744109730105\n","Validation Accuracy Epoch: 75.70121493925303\n","Epoch 13 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:27,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 15: 0.16493606025908403\n","Training Accuracy Epoch 15: 94.72736818420461 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 1.3082461107502148\n","Validation Accuracy Epoch: 76.30868456577171\n","Epoch 14 done!\n"]},{"output_type":"display_data","data":{"text/html":["Finishing last run (ID:3um7j2gy) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 914... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94bf6ce8f1e94989910b045a01318f5f","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.18MB of 0.18MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train_Acc</td><td>▁▁▂▃▃▄▅▆▆▆▇▇▇▇█</td></tr><tr><td>Train_Loss</td><td>██▇▆▆▅▄▄▃▃▂▂▂▂▁</td></tr><tr><td>Val_Acc</td><td>▁▂▃▃▅▅▆▇▇▇█████</td></tr><tr><td>Val_Loss</td><td>█▇▅▄▃▃▁▁▂▁▁▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>14</td></tr><tr><td>Train_Acc</td><td>94.72737</td></tr><tr><td>Train_Loss</td><td>0.16494</td></tr><tr><td>Val_Acc</td><td>76.30868</td></tr><tr><td>Val_Loss</td><td>1.30825</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">3-Fold</strong>: <a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/3um7j2gy\" target=\"_blank\">https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/3um7j2gy</a><br/>\n","Find logs at: <code>./wandb/run-20211020_041851-3um7j2gy/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Successfully finished last run (ID:3um7j2gy). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/226c1s86\" target=\"_blank\">3-Fold</a></strong> to <a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training fold 2...\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:28,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 1: 1.33731226232428\n","Training Accuracy Epoch 1: 63.61420482243972 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.27it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.8241451653412921\n","Validation Accuracy Epoch: 77.77694442361059\n","Epoch 0 done!\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:29,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 2: 1.2021914892698664\n","Training Accuracy Epoch 2: 65.70292871339109 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.25it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.7738266708664328\n","Validation Accuracy Epoch: 78.62446561164029\n","Epoch 1 done!\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:31,  2.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 3: 1.1412145758397434\n","Training Accuracy Epoch 3: 67.09791127610904 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.722795703580125\n","Validation Accuracy Epoch: 79.65949148728718\n","Epoch 2 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:32,  2.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 4: 1.0873742508688014\n","Training Accuracy Epoch 4: 68.6541418232272 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.7164655997991848\n","Validation Accuracy Epoch: 79.7719942998575\n","Epoch 3 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:32,  2.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 5: 1.0867703663208703\n","Training Accuracy Epoch 5: 68.49289383882702 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.7120537852926506\n","Validation Accuracy Epoch: 79.85449636240907\n","Epoch 4 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:33,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 6: 1.0769069555031732\n","Training Accuracy Epoch 6: 68.5491431357108 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.7058718304196707\n","Validation Accuracy Epoch: 80.03450086252157\n","Epoch 5 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:34,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 7: 1.0753666730469118\n","Training Accuracy Epoch 7: 68.46664416694792 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.7014249417957642\n","Validation Accuracy Epoch: 80.12450311257781\n","Epoch 6 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:35,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 8: 1.0684450884010523\n","Training Accuracy Epoch 8: 68.87163910451119 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:56,  7.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6962335226561526\n","Validation Accuracy Epoch: 80.30450761269032\n","Epoch 7 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:35,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 9: 1.0595394133466693\n","Training Accuracy Epoch 9: 69.10038624517193 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6910312062294649\n","Validation Accuracy Epoch: 80.36450911272782\n","Epoch 8 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:36,  2.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 10: 1.056045351463946\n","Training Accuracy Epoch 10: 69.32163347958151 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6880279104504511\n","Validation Accuracy Epoch: 80.46201155028876\n","Epoch 9 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:37,  2.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 11: 1.0476182475641378\n","Training Accuracy Epoch 11: 69.34788315146061 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6865163375299683\n","Validation Accuracy Epoch: 80.50701267531689\n","Epoch 10 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:38,  2.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 12: 1.0467485961133876\n","Training Accuracy Epoch 12: 69.50538118273522 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:56,  7.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6862635145665145\n","Validation Accuracy Epoch: 80.51451286282158\n","Epoch 11 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:38,  2.39it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 13: 1.0521531377141893\n","Training Accuracy Epoch 13: 69.15663554205572 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6852883764987083\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 12 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:40,  2.38it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 14: 1.0465295095427993\n","Training Accuracy Epoch 14: 69.40788240146998 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6852768537112706\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 13 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:40,  2.38it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 15: 1.0446322481647965\n","Training Accuracy Epoch 15: 69.35538305771178 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.685009884659192\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 14 done!\n"]},{"output_type":"display_data","data":{"text/html":["Finishing last run (ID:226c1s86) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 2499... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21ca3a292a6443d3847747d56b6b33d0","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Train_Acc</td><td>▁▃▅▇▇▇▇▇███████</td></tr><tr><td>Train_Loss</td><td>█▅▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Val_Acc</td><td>▁▃▆▆▆▇▇▇███████</td></tr><tr><td>Val_Loss</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>14</td></tr><tr><td>Train_Acc</td><td>69.35538</td></tr><tr><td>Train_Loss</td><td>1.04463</td></tr><tr><td>Val_Acc</td><td>80.52201</td></tr><tr><td>Val_Loss</td><td>0.68501</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">3-Fold</strong>: <a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/226c1s86\" target=\"_blank\">https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/226c1s86</a><br/>\n","Find logs at: <code>./wandb/run-20211020_073816-226c1s86/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Successfully finished last run (ID:226c1s86). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition/runs/3ldjmb5j\" target=\"_blank\">3-Fold</a></strong> to <a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training fold 3...\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:41,  2.38it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 1: 1.0775974182469015\n","Training Accuracy Epoch 1: 68.68789140135749 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.23it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6851272200562543\n","Validation Accuracy Epoch: 80.51451286282158\n","Epoch 0 done!\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:42,  2.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 2: 1.0758572966843647\n","Training Accuracy Epoch 2: 68.6278921513481 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.23it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.685150904317411\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 1 done!\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:43,  2.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 3: 1.0760115024817511\n","Training Accuracy Epoch 3: 68.48164397945025 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:56,  7.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6857440559823307\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 2 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:43,  2.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 4: 1.0750920223882259\n","Training Accuracy Epoch 4: 68.72539093261334 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6852922149770837\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 3 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:44,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 5: 1.0758782068661894\n","Training Accuracy Epoch 5: 68.56414294821315 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6854410977225652\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 4 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:46,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 6: 1.0764268271370283\n","Training Accuracy Epoch 6: 68.72164097948776 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6854717819917974\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 5 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:46,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 7: 1.0739450334751757\n","Training Accuracy Epoch 7: 68.5491431357108 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6848201484595843\n","Validation Accuracy Epoch: 80.52951323783094\n","Epoch 6 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:47,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 8: 1.074782835235836\n","Training Accuracy Epoch 8: 68.19289758878014 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6853613752862818\n","Validation Accuracy Epoch: 80.52951323783094\n","Epoch 7 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:47,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 9: 1.078146192561958\n","Training Accuracy Epoch 9: 68.18539768252897 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6849365721164132\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 8 done!\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:48,  2.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 10: 1.0776059926271295\n","Training Accuracy Epoch 10: 68.50039374507818 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6844365377809932\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 9 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:47,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 11: 1.0720733159590998\n","Training Accuracy Epoch 11: 68.6053924325946 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6847465351956497\n","Validation Accuracy Epoch: 80.52201305032627\n","Epoch 10 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:48,  2.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 12: 1.0746205815510186\n","Training Accuracy Epoch 12: 68.56414294821315 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:54,  7.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6853468014771561\n","Validation Accuracy Epoch: 80.52951323783094\n","Epoch 11 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:49,  2.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 13: 1.0737901773989809\n","Training Accuracy Epoch 13: 68.17039787002662 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6848340972954278\n","Validation Accuracy Epoch: 80.52951323783094\n","Epoch 12 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:50,  2.34it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 14: 1.073250263839978\n","Training Accuracy Epoch 14: 68.51164360445495 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6855671092671313\n","Validation Accuracy Epoch: 80.52951323783094\n","Epoch 13 done!\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [11:51,  2.34it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Training Loss Epoch 15: 1.0691849492718233\n","Training Accuracy Epoch 15: 68.56039299508757 \n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","834it [01:55,  7.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Validation Loss Epoch : 0.6843221049970217\n","Validation Accuracy Epoch: 80.52951323783094\n","Epoch 14 done!\n"]}]},{"cell_type":"markdown","metadata":{"id":"uqUG7OGFgOOW"},"source":["### K-Fold (RoBERTa large)"]},{"cell_type":"code","metadata":{"id":"MKHIoJWlgOOX","executionInfo":{"status":"ok","timestamp":1635593535273,"user_tz":-480,"elapsed":9,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}}},"source":["# Set K-fold\n","kf = KFold(n_splits=3, shuffle=True, random_state=42)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"id":"zvvjdVnWgOOX","executionInfo":{"status":"ok","timestamp":1635593542123,"user_tz":-480,"elapsed":6859,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"}},"outputId":"aa36b97b-290a-4c49-e407-97acea599920"},"source":["# Setup wandb for logging\n","import wandb\n","\n","wandb.login()"],"execution_count":34,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222,"referenced_widgets":["bd0464364ccc49809c40387b85ed30ae","fc28f3fa07724fbab86046a01f8c158e","7c95bd7b0f1748ad81f169231d0dd4b5","a38c15fab6e345ef9b16a28a2fb570ea","402890aac5814202a26a17752f74ed74","3653571f75484cd0b0d540e1406d4e77","037b307010564c51985fd4f03ce4f077","5874afd1dccf4112a80ed280a64bd833","c7bfa66570354a369605ec4cedf184f5","7a6dcfa8dede460ca3bb47a4e0d524b6","d99c1ddedb014c128772f5d8658d7b28"]},"id":"GyNFgPk5gOOY","outputId":"fd6a7190-51a2-4c1c-a732-b186dce4349a"},"source":["EPOCHS=15\n","f = 1\n","df = df.reset_index(drop=True)\n","\n","for train_index, val_index in kf.split(df):\n","\n","  model2 = RobertaClass()\n","  model2.to(device)\n","\n","  # Optimizer\n","  optimizer = torch.optim.AdamW(params=model2.parameters(), lr=LEARNING_RATE)\n","  # Reduce LR on plateau\n","  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n","\n","  # Init wandb for logging\n","  wandb.init(project=\"Text_Emotion_Recognition_RoBERTa_large2\", name=f\"3-Fold\")\n","\n","  train2 = df.iloc[train_index]\n","  test2 = df.iloc[val_index]\n","\n","  train2 = train2.reset_index(drop=True)\n","  test2 = df.drop(train2.index).reset_index(drop=True)\n","\n","  training_set = SentimentData(train2, tokenizer2, MAX_LEN)\n","  testing_set = SentimentData(test2, tokenizer2, MAX_LEN)\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","\n","  print(f\"Training fold {f}...\")\n","\n","  for epoch in range(0, EPOCHS):\n","    \n","    # Train\n","    train_acc, train_loss = train(model2, epoch, training_loader)\n","    # Val\n","    val_acc, val_loss = valid(model2, testing_loader)\n","    print(f\"Epoch {epoch+1} done!\")\n","    # Log metrics\n","    wandb.log({\"Train_Loss\": train_loss, \"Val_Loss\": val_loss, \"Train_Acc\": train_acc, \"Val_Acc\": val_acc, \"Epoch\": epoch})   \n","\n","  f+=1"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd0464364ccc49809c40387b85ed30ae","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwasabee\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition_RoBERTa_large2/runs/8odebbej\" target=\"_blank\">3-Fold</a></strong> to <a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition_RoBERTa_large2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training fold 1...\n"]},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","10it [00:10,  1.01it/s]"]}]},{"cell_type":"markdown","metadata":{"id":"jUfUWS5-It4a"},"source":["### Save model"]},{"cell_type":"code","metadata":{"id":"X9PXHnI-IowG"},"source":["# # Base model\n","# rob_base = model\n","\n","# torch.save(rob_base, '/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/roberta_base/roberta_base.bin')\n","# tokenizer.save_vocabulary('/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/roberta_base/')\n","\n","# Large model\n","rob_large = model2\n","torch.save(rob_large, '/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/roberta_large/roberta_large.bin')\n","tokenizer2.save_vocabulary('/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/roberta_large/')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lW0sM4IRQX7a"},"source":["### Inference"]},{"cell_type":"markdown","metadata":{"id":"LEmMcwr7UICq"},"source":["#### Load model, tokenizer, labels"]},{"cell_type":"code","metadata":{"id":"aaM7DP90W5kC"},"source":["!cp '/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/roberta_sent.bin' -d '/content/roberta_sent.bin'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzQhFQcvXshC"},"source":["!cp '/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/vocab.json' -d '/content/vocab.json'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVfm8mL3Xsmv"},"source":["!cp '/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/merges.txt' -d '/content/merges.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UBp5LWBbZFOr"},"source":["class RobertaClass(torch.nn.Module):\n","    def __init__(self):\n","        super(RobertaClass, self).__init__()\n","        self.l1 = RobertaModel.from_pretrained(\"/content/roberta_sent.bin\")\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, 13)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"57V7Rtl0XhNT"},"source":["saved_model2 = torch.load('/content/roberta_sent.bin')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mes6nLXTXnp1","executionInfo":{"status":"ok","timestamp":1634806099775,"user_tz":-480,"elapsed":29300,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"}},"outputId":"e6e40695-065e-4251-9b6f-64e4477f0819"},"source":["tokenizer2 = RobertaTokenizer.from_pretrained(\"/content/\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["file /content/config.json not found\n"]}]},{"cell_type":"code","metadata":{"id":"c8x6U8DKVuUj"},"source":["labels_dict = {'anger': 12,\n"," 'boredom': 10,\n"," 'empty': 0,\n"," 'enthusiasm': 2,\n"," 'fun': 7,\n"," 'happiness': 9,\n"," 'hate': 8,\n"," 'love': 6,\n"," 'neutral': 3,\n"," 'relief': 11,\n"," 'sadness': 1,\n"," 'surprise': 5,\n"," 'worry': 4}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbJwWsZ7UKFL"},"source":["#### Function to get encode user input"]},{"cell_type":"code","metadata":{"id":"mnFC7cIeOPcF"},"source":["def get_inputs(text, tokenizer):\n","\n","  inps = tokenizer.encode_plus(\n","              list(text),\n","              None,\n","              add_special_tokens=True,\n","              max_length=256,\n","              pad_to_max_length=True,\n","              return_token_type_ids=True,\n","              return_tensors='pt'\n","          )\n","  \n","  inp_tok = inps['input_ids'].to('cuda', dtype = torch.long)\n","  ids = inps['attention_mask'].to('cuda', dtype = torch.long)\n","  segments = inps['token_type_ids'].to('cuda', dtype = torch.long)\n","\n","  return inp_tok, ids, segments\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAw_lBiRV-08"},"source":["def cleaner(user_text):\n","\n","  wordnet_lemmatizer = WordNetLemmatizer()\n","\n","  stop = stopwords.words('english')\n","\n","  for punct in punctuation:\n","      stop.append(punct)\n","\n","  def clean(x, stop_words):\n","      word_tokens = WordPunctTokenizer().tokenize(x.lower())\n","      x = [regex.sub(u'\\p{^Latin}', u'', w) for w in word_tokens if w.isalpha() and len(w) > 2]\n","      return \" \".join(x)\n","\n","  cleaned_user = clean(user_text, stop) \n","  \n","  return cleaned_user"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2KsocB1UQBz"},"source":["def get_sentiment(user_input):\n","\n","  # Define empty list to store emotions\n","  sentiment = []\n","\n","  user_input = cleaner(user_input)\n","\n","  # Pass user input to encode text\n","  inp_tok, ids, segments = get_inputs(user_input, tokenizer2)\n","\n","  # Get predictions\n","  preds = saved_model2(inp_tok, ids, segments)\n","\n","  # Get max pred\n","  # big_val, big_idx = torch.max(preds.data, dim=1)\n","  big_val, big_idx = torch.topk(preds.data, k=3, dim=1)\n","\n","  for x in range(len(big_idx[0])):\n","    sentiment.append(list(labels_dict.keys())[list(labels_dict.values()).index(big_idx[0][x].item())])\n","\n","  print(\"Predicted Sentiment:\", sentiment)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_KQAn53SMV5"},"source":["# write to get user input here\n","# user_input = input(\"Enter some text: \")\n","user_input = 'missed the bus.... shit!'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J47UT-t9SIfi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634806466286,"user_tz":-480,"elapsed":355,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"}},"outputId":"a80d2f8a-3d69-4388-f688-85855528c949"},"source":["get_sentiment(user_input)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Sentiment: ['sadness', 'neutral', 'worry']\n"]}]},{"cell_type":"code","metadata":{"id":"okv4zPwmQXSC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634794950040,"user_tz":-480,"elapsed":5,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"}},"outputId":"fe93b98d-57da-490c-b26e-cf9b73c3da9d"},"source":["labels_dict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'anger': 12,\n"," 'boredom': 10,\n"," 'empty': 0,\n"," 'enthusiasm': 2,\n"," 'fun': 7,\n"," 'happiness': 9,\n"," 'hate': 8,\n"," 'love': 6,\n"," 'neutral': 3,\n"," 'relief': 11,\n"," 'sadness': 1,\n"," 'surprise': 5,\n"," 'worry': 4}"]},"metadata":{},"execution_count":183}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkMtSETJR3pK","executionInfo":{"status":"ok","timestamp":1634794965966,"user_tz":-480,"elapsed":718,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"}},"outputId":"654a81c4-b675-4d9d-8d47-9623768e7478"},"source":["from random import randint\n","\n","r_int = randint(0,100)\n","\n","print(df.sentiment[r_int])\n","print(df.content_cleaned[r_int])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["neutral\n","missed the bus\n"]}]}]}