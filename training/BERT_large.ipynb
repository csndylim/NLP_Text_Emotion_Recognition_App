{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15649,"status":"ok","timestamp":1635582426447,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"v1L-D4onRFZr","outputId":"b5066a31-8337-40c3-9a1f-a99a15ffd84b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"OW9pCCPaQJa6"},"source":["### Download dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5795,"status":"ok","timestamp":1635582432239,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"wjcAMvXqtRSn","outputId":"000a7249-91c3-45ff-ee4c-9c6c598d966a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 62.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 50.5 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.17\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 61.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.2\n"]}],"source":["!pip install --upgrade transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6558,"status":"ok","timestamp":1635582438794,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"ENUrJ4ywL9ti","outputId":"cf686028-59ce-4ecd-9c14-4f884c1e982c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.9.0+cu111)\n","Collecting boto3\n","  Downloading boto3-1.19.7-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 40.4 MB/s \n","\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.0.46)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 39.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.23.0,>=1.22.7\n","  Downloading botocore-1.22.7-py3-none-any.whl (8.1 MB)\n","\u001b[K     |████████████████████████████████| 8.1 MB 35.4 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 75.4 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.7->boto3->pytorch-transformers) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.7->boto3->pytorch-transformers) (1.15.0)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 71.9 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.0.1)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, boto3, pytorch-transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.19.7 botocore-1.22.7 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sentencepiece-0.1.96 urllib3-1.25.11\n"]}],"source":["!pip install pytorch-transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14043,"status":"ok","timestamp":1635582452834,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"mITSXunyLVR1","outputId":"2712ee53-2f07-44b8-f6f2-d0de5329a0b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["4.12.2\n"]}],"source":["from transformers import __version__\n","print(__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2770,"status":"ok","timestamp":1635582455600,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"tNnZqTbH1Owv","outputId":"f3b6c6c7-e0a1-4713-9e82-2015689d5015"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6877,"status":"ok","timestamp":1635582462473,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"6MiGYWogQK7L","outputId":"798d40eb-55c8-472d-f1f0-fc0b80487c54"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wandb\n","  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 75.9 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 7.9 MB/s \n","\u001b[?25hCollecting configparser>=3.8.1\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 71.3 MB/s \n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=c4035bebc158c3431875a9e9b71c0a582431e2e4bf9a015fc32d26aa50a2880f\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=4daa165d13c426f23ee7fd7fcf2f50d656d0ab44e417e89eb0d96f78ebb894a8\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"]}],"source":["!pip install wandb"]},{"cell_type":"markdown","metadata":{"id":"beCCkJ6DQBtf"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2149,"status":"ok","timestamp":1635582464613,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"GweU62UIQIqJ","outputId":"94b6f1f6-6d80-486d-831c-9d494df7cc33"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import regex\n","from tqdm import tqdm\n","\n","from sklearn import preprocessing, metrics\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n","from torch.utils.data import Dataset, DataLoader\n","\n","from tensorflow.keras.utils import to_categorical\n","from keras.preprocessing.sequence import pad_sequences\n","\n","import tensorflow as tf\n","import transformers\n","from transformers import XLNetForSequenceClassification, XLNetTokenizer, TFXLNetModel, XLNetModel, AdamW, get_linear_schedule_with_warmup\n","from transformers import RobertaModel, RobertaTokenizer\n","\n","import nltk\n","from nltk.corpus import stopwords \n","from nltk.tokenize import WordPunctTokenizer\n","from string import punctuation\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1635582464614,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"cupnx6q_vNb2","outputId":"2f90c3d9-b7e0-4437-b38a-ebbfe9886201"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.9.0+cu111\n"]}],"source":["print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tayL3He7uvF8"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_9qOO8LiN2p"},"outputs":[],"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"0KgP7rRLQFZO"},"source":["### Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AfutfGKBQAlH"},"outputs":[],"source":["f_path = '/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/dataset/crowdflower_text_emotion.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XgpvlBcMQAnH"},"outputs":[],"source":["df = pd.read_csv(f_path)"]},{"cell_type":"markdown","metadata":{"id":"OuzN46oCQMOc"},"source":["### Data preprocessing and analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1635582466235,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"oGKcv1-GQApG","outputId":"97ee98eb-2173-4f3a-cd6f-b4aa515980cd"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>sentiment</th>\n","      <th>author</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1956967341</td>\n","      <td>empty</td>\n","      <td>xoshayzers</td>\n","      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1956967666</td>\n","      <td>sadness</td>\n","      <td>wannamama</td>\n","      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1956967696</td>\n","      <td>sadness</td>\n","      <td>coolfunky</td>\n","      <td>Funeral ceremony...gloomy friday...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1956967789</td>\n","      <td>enthusiasm</td>\n","      <td>czareaquino</td>\n","      <td>wants to hang out with friends SOON!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1956968416</td>\n","      <td>neutral</td>\n","      <td>xkilljoyx</td>\n","      <td>@dannycastillo We want to trade with someone w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     tweet_id  ...                                            content\n","0  1956967341  ...  @tiffanylue i know  i was listenin to bad habi...\n","1  1956967666  ...  Layin n bed with a headache  ughhhh...waitin o...\n","2  1956967696  ...                Funeral ceremony...gloomy friday...\n","3  1956967789  ...               wants to hang out with friends SOON!\n","4  1956968416  ...  @dannycastillo We want to trade with someone w...\n","\n","[5 rows x 4 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1635582466235,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"T3uI-NOsQArQ","outputId":"85f2cf22-5445-4617-a2ea-3dd2182eaf52"},"outputs":[{"name":"stdout","output_type":"stream","text":["['empty' 'sadness' 'enthusiasm' 'neutral' 'worry' 'surprise' 'love' 'fun'\n"," 'hate' 'happiness' 'boredom' 'relief' 'anger']\n"]}],"source":["# Check emotions labels\n","\n","labels = df.sentiment.unique()\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KG7DyxzPQAtI"},"outputs":[],"source":["# Remove irrelevant columns\n","df = df.drop(columns=['tweet_id', 'author'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1635582466236,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"IA3PHfffNONe","outputId":"83cc1beb-7353-4f3a-8c2a-c141bc33a944"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Check for null cells\n","df['sentiment'].isnull().values.any()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lw6l6A1i7vUk"},"outputs":[],"source":["# Remove stop words, lemmatize, clean text\n","\n","wordnet_lemmatizer = WordNetLemmatizer()\n","\n","stop = stopwords.words('english')\n","\n","for punct in punctuation:\n","    stop.append(punct)\n","\n","def clean(x, stop_words):\n","    word_tokens = WordPunctTokenizer().tokenize(x.lower())\n","    x = [regex.sub(u'\\p{^Latin}', u'', w) for w in word_tokens if w.isalpha() and len(w) > 2]\n","    return \" \".join(x)\n","\n","df[\"content_cleaned\"] = df.content.apply(lambda x : clean(x, stop)) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YNrhUEtWNOPz"},"outputs":[],"source":["# Check len of each content\n","df['content_count'] = df['content_cleaned'].str.split(\" \").str.len()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1635582468288,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"BKJ0zVzG_4Di","outputId":"35050cc3-e556-440b-c8c8-437ece74c477"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>content</th>\n","      <th>content_cleaned</th>\n","      <th>content_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>empty</td>\n","      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n","      <td>tiffanylue know was listenin bad habit earlier...</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sadness</td>\n","      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n","      <td>layin bed with headache ughhhh waitin your call</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sadness</td>\n","      <td>Funeral ceremony...gloomy friday...</td>\n","      <td>funeral ceremony gloomy friday</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>enthusiasm</td>\n","      <td>wants to hang out with friends SOON!</td>\n","      <td>wants hang out with friends soon</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>neutral</td>\n","      <td>@dannycastillo We want to trade with someone w...</td>\n","      <td>dannycastillo want trade with someone who has ...</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sentiment  ... content_count\n","0       empty  ...            12\n","1     sadness  ...             8\n","2     sadness  ...             4\n","3  enthusiasm  ...             6\n","4     neutral  ...            12\n","\n","[5 rows x 4 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"RJ9ZRe_4BGGf"},"source":["### Label encoding classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MdPWKgwWF_d-"},"outputs":[],"source":["labels_dict = dict(zip(labels, (x for x in range(len(labels)) )))\n","df['sentiment_val'] = df['sentiment'].map(labels_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLvTvEDeAggz"},"outputs":[],"source":["df = df.drop(columns=['sentiment', 'content_count', 'content'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1635582468289,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"phXezD-LAqab","outputId":"eb4195a7-0b2e-412f-ca1c-9ee99e46eacf"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content_cleaned</th>\n","      <th>sentiment_val</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tiffanylue know was listenin bad habit earlier...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>layin bed with headache ughhhh waitin your call</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>funeral ceremony gloomy friday</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wants hang out with friends soon</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dannycastillo want trade with someone who has ...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     content_cleaned  sentiment_val\n","0  tiffanylue know was listenin bad habit earlier...              0\n","1    layin bed with headache ughhhh waitin your call              1\n","2                     funeral ceremony gloomy friday              1\n","3                   wants hang out with friends soon              2\n","4  dannycastillo want trade with someone who has ...              3"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"Iz3SZaTNYQQM"},"source":["### Prep data for training/validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KuaiJhtENUQ"},"outputs":[],"source":["class SentimentData(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe.content_cleaned\n","        self.targets = self.data.sentiment_val\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4xJ5o_xiXM1"},"outputs":[],"source":["# Batch Size\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YULG6eb_KjTz"},"outputs":[],"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 2\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 2\n","                }"]},{"cell_type":"markdown","metadata":{"id":"Vl9Ax3Nw_BZn"},"source":["### BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WbbILdHfEmMy"},"outputs":[],"source":["from transformers import BertTokenizerFast, BertForSequenceClassification, AutoModel, BertConfig, BertModel"]},{"cell_type":"markdown","metadata":{"id":"uvMqzCKtTuEa"},"source":["#### Large-cased"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248,"referenced_widgets":["3f560af2be2744b7924f431889f6bb43","ba45b7fb19704369a8aa3dcb9709d3e7","6feeebc691104a64b768e9ee85438267","75bbf1de3ec44c9f8f2676451b7e0986","30ba4232670947e1a4d39813aeb405bf","406e51c268c744d3bba7c6b4004269b5","15d34fd248e047ec942422052c46c991","50359db47c5f4fd9ba4ccdf378bdcac5","0f9d41b523774faaa3ee1e3608205dae","3edb60b9bfee41299b3286d3e165e847","db02a3ea5a1d4a24af5d649367d73cc4","77db3fcb103c4466a7f19bd034e38a19","98f18e989e3f46f6a7a6c38f56f11467","b7a295763aa042f38004b05b610eb755","b02a4876a3604e18be4bd80a07c1c3d2","7e56aa9a0c9d4234be4d7e7f3f717b88","32be20b70f47403482814aaa588ba6bf","ea82d49fa4c244ab93f2caef2550dac7","6a317fe36dd8482a905feec7ea6cec82","84b130932eaf49e1a745502a945efe08","aa1599d5149e45caa3001f6ff3742432","cb4f26aa0ce641c394b7aa687cb27086","0335994ccfab42a7b2dcc1ed8be87c85","fd4ef819bc644ad787ffeba28cf8414e","58834e1349b54d06a5cd83737f90a1f4","1d0290a2cb5e4187a0bb0f5669eb9e6e","e81f9de618c54e85845e1c60e1d65ae3","935fcf0ba86744cd9c7f0b34f061985a","178f1efc53794c3180633ab708e72c37","1c59b9bebcca48b0b9a255baf5580a11","24667d2ed7714e429970713ce65d9926","ee592576407d4cb0b28bf8015366f198","e9e7eca1da414b2a9126fb0ec287912f","fddb3355d84e4aadada3367f6fb96fe6","ab1d104f4c6b455b8817f225ef158adc","0a8eecc1f56c4b69b5672cd73b01fb79","4a5e18ffe8f54866822aca2745f3b243","f7169b627b384f83939bf64e23feda49","a672c0b1171e41afb3fb041002c9289f","6548e249cac849c8a492eca23209dae9","2d7ff72b31fe438982898a2a0135af24","fc0b31ef33ad4f3496a29fe7ea5315df","61dd9147db3140b1b539718a6562ff63","0406e3f6db304488875f229bc8b0040b","200a7bb9305348c9a80106df11f27ae0","44700002ab934fa7937debe909f09120","bedacf9cd5574396b582366b87339d9b","d37a851827ef40f0916d289b4024b33f","ea1651d044314cf7830e210cb0445a6f","255d3c230f7c401f8fd821b8f91b9f20","800cfd40a89644639a5fd2527ea834f3","099db3381ba1422f95fd774510dd3104","025a2a0e3f6f4047889e7e02d8f20e4f","32de94e0f34c4dcdab4600d2bfffc19e","98e0dc3b290042d7947e8093bb24e738"]},"executionInfo":{"elapsed":37992,"status":"ok","timestamp":1635582506271,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"smF12RpgTuEa","outputId":"b210d61a-921b-48f9-f13d-0b8b07c4973c"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f560af2be2744b7924f431889f6bb43","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77db3fcb103c4466a7f19bd034e38a19","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0335994ccfab42a7b2dcc1ed8be87c85","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fddb3355d84e4aadada3367f6fb96fe6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"200a7bb9305348c9a80106df11f27ae0","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-large-cased')\n","bert = AutoModel.from_pretrained('bert-large-cased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nY72uEITuEb"},"outputs":[],"source":["class BERT(nn.Module):\n","\n","    def __init__(self, config):\n","        super(BERT, self).__init__()\n","        self.num_labels = config.num_labels\n","        self.bert = BertModel(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","\n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None,\n","                position_ids=None, head_mask=None):\n","      \n","        # Forward pass through pre-trained BERT\n","        outputs = self.bert(input_ids, position_ids=position_ids, token_type_ids=token_type_ids,\n","                            attention_mask=attention_mask, head_mask=head_mask)\n","\n","        pooler = outputs[-1]\n","        pooler = self.pre_classifier(pooler\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        \n","        return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xce16vFTuEb"},"outputs":[],"source":["config = BertConfig(hidden_size=768,\n","                    hidden_dropout_prob=0.3,\n","                    num_labels=13)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sFb6HIoTuEb"},"outputs":[],"source":["# model = BERT(config)\n","\n","# # push the model to GPU\n","# model = model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"yJR_LDAQNjaR"},"source":["### Train/Eval functions"]},{"cell_type":"markdown","metadata":{"id":"6sBbhhzJiENf"},"source":["#### Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KkXQL8QDiDwh"},"outputs":[],"source":["LEARNING_RATE = 1e-05\n","MAX_LEN = 256\n","\n","# Multi class loss\n","loss_function = torch.nn.CrossEntropyLoss()\n","\n","# Accuracy function\n","def calcuate_accuracy(preds, targets):\n","    n_correct = (preds==targets).sum().item()\n","    return n_correct"]},{"cell_type":"markdown","metadata":{"id":"hpDp_VFKjI3_"},"source":["#### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWl0UERQi_3C"},"outputs":[],"source":["# For BERT large\n","def train(model, epoch, training_loader):\n","\n","  tr_loss = 0\n","  n_correct = 0\n","  nb_tr_steps = 0\n","  nb_tr_examples = 0\n","\n","  # Tell wandb to watch this model train\n","  # wandb.watch(model)\n","\n","  model.train()\n","\n","  for _, data in tqdm(enumerate(training_loader, 0)):\n","\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.long)\n","\n","    outputs = model(ids, mask, token_type_ids)\n","    loss = loss_function(outputs, targets)\n","    tr_loss += loss.item()\n","    big_val, big_idx = torch.max(outputs.data, dim=1)\n","    n_correct += calcuate_accuracy(big_idx, targets)\n","\n","    nb_tr_steps += 1\n","    nb_tr_examples+=targets.size(0)\n","    \n","    if _%5000==0:\n","        loss_step = tr_loss/nb_tr_steps\n","        accu_step = (n_correct*100)/nb_tr_examples \n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    # Optimizer \n","    optimizer.step()\n","\n","  print('\\n')\n","  epoch_loss = tr_loss/nb_tr_steps\n","  epoch_accu = (n_correct*100)/nb_tr_examples\n","  print(f\"Training Loss Epoch {epoch+1}: {epoch_loss}\")\n","  print(f\"Training Accuracy Epoch {epoch+1}: {epoch_accu} \\n\")\n","  \n","  return epoch_accu, epoch_loss"]},{"cell_type":"markdown","metadata":{"id":"5Gpk3QhujbD2"},"source":["#### Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGGf2WT9jKyS"},"outputs":[],"source":["def valid(model, testing_loader):\n","\n","    n_correct = 0; \n","    n_wrong = 0; \n","    total = 0; \n","    tr_loss=0; \n","    nb_tr_steps=0; \n","    nb_tr_examples=0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for _, data in tqdm(enumerate(testing_loader, 0)):\n","\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","            targets = data['targets'].to(device, dtype = torch.long)\n","            outputs = model(ids, mask, token_type_ids).squeeze()\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calcuate_accuracy(big_idx, targets)\n","\n","            nb_tr_steps += 1\n","            nb_tr_examples+=targets.size(0)\n","            \n","            if _%5000==0:\n","                loss_step = tr_loss/nb_tr_steps\n","                accu_step = (n_correct*100)/nb_tr_examples\n","        # Reduce LR on val loss plateau\n","        scheduler.step(loss)\n","\n","    print('\\n')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Validation Loss Epoch : {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","    \n","    return epoch_accu, epoch_loss\n"]},{"cell_type":"markdown","metadata":{"id":"uqUG7OGFgOOW"},"source":["### K-Fold (BERT large-cased)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKHIoJWlgOOX"},"outputs":[],"source":["# Set K-fold\n","kf = KFold(n_splits=3, shuffle=True, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"elapsed":8648,"status":"ok","timestamp":1635582514909,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuVKoewgt_BmmcXNGiijpzl86ftU2fiZfYsoik5A=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"zvvjdVnWgOOX","outputId":"ab758bdf-ab68-48c3-d280-b5905e9a7a59"},"outputs":[{"data":{"application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# # Setup wandb for logging\n","# import wandb\n","\n","# wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"GyNFgPk5gOOY","outputId":"f2eaf1dc-9c49-4b5d-fca3-5e584461321d"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwasabee\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition_BERT_large_cased3/runs/2ibod1yt\" target=\"_blank\">3-Fold</a></strong> to <a href=\"https://wandb.ai/wasabee/Text_Emotion_Recognition_BERT_large_cased3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training fold 1...\n"]},{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:11,  4.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 1: 2.2705960726051466\n","Training Accuracy Epoch 1: 19.324233105827645 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:58, 14.03it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 2.2811747494041383\n","Validation Accuracy Epoch: 10.866956652167392\n","Epoch 1 done!\n"]},{"name":"stderr","output_type":"stream","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:12,  4.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 2: 2.227786845587368\n","Training Accuracy Epoch 2: 20.00675016875422 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 13.92it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 2.23591649975688\n","Validation Accuracy Epoch: 18.56907154642268\n","Epoch 2 done!\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:14,  4.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 3: 2.141081053229528\n","Training Accuracy Epoch 3: 24.18060451511288 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 14.00it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 2.0607968185501466\n","Validation Accuracy Epoch: 27.703614819259037\n","Epoch 3 done!\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:14,  4.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 4: 2.0816399841588917\n","Training Accuracy Epoch 4: 25.864396609915246 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 14.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 2.038192905418588\n","Validation Accuracy Epoch: 27.876106194690266\n","Epoch 4 done!\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:15,  4.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 5: 2.0208754539132188\n","Training Accuracy Epoch 5: 28.628215705392634 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 13.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 2.004293140924542\n","Validation Accuracy Epoch: 32.818359082045895\n","Epoch 5 done!\n"]},{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:16,  4.53it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 6: 1.9679396749436677\n","Training Accuracy Epoch 6: 31.407035175879397 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 13.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 2.004067539310627\n","Validation Accuracy Epoch: 32.683365831708414\n","Epoch 6 done!\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:16,  4.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 7: 1.9254226254251237\n","Training Accuracy Epoch 7: 33.50333758343959 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 13.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 1.9662674768784838\n","Validation Accuracy Epoch: 36.74066296685166\n","Epoch 7 done!\n"]},{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:17,  4.52it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 8: 1.8896725064955862\n","Training Accuracy Epoch 8: 35.20963024075602 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 13.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 1.9094000882064073\n","Validation Accuracy Epoch: 37.393130343482824\n","Epoch 8 done!\n"]},{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:19,  4.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 9: 1.8532941538771255\n","Training Accuracy Epoch 9: 36.5859146478662 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 13.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 1.841278607321844\n","Validation Accuracy Epoch: 40.86545672716364\n","Epoch 9 done!\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:19,  4.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 10: 1.8196589519109423\n","Training Accuracy Epoch 10: 38.082202055051376 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [01:59, 13.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 1.8545252017153904\n","Validation Accuracy Epoch: 41.69041547922604\n","Epoch 10 done!\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:21,  4.50it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 11: 1.775735985163664\n","Training Accuracy Epoch 11: 39.81849546238656 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [02:00, 13.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 1.8605611429789428\n","Validation Accuracy Epoch: 39.39553022348883\n","Epoch 11 done!\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","3334it [12:22,  4.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Training Loss Epoch 12: 1.7376379383025087\n","Training Accuracy Epoch 12: 41.00727518187955 \n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1667it [02:00, 13.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Validation Loss Epoch : 1.7705285341959909\n","Validation Accuracy Epoch: 42.852857357132145\n","Epoch 12 done!\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","1297it [04:48,  4.56it/s]"]}],"source":["EPOCHS=15\n","f = 1\n","df = df.reset_index(drop=True)\n","\n","for train_index, val_index in kf.split(df):\n","\n","  # Init model\n","  model = BERT(config)\n","  # push the model to GPU\n","  model = model.to(device)\n","  # Optimizer\n","  optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n","  # Reduce LR on plateau\n","  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n","\n","  # Init wandb for logging\n","  # wandb.init(project=\"Text_Emotion_Recognition_BERT_large_cased3\", name=f\"3-Fold\")\n","\n","  train2 = df.iloc[train_index]\n","  test2 = df.iloc[val_index]\n","\n","  train2 = train2.reset_index(drop=True)\n","  test2 = df.drop(train2.index).reset_index(drop=True)\n","\n","  training_set = SentimentData(train2, tokenizer, MAX_LEN)\n","  testing_set = SentimentData(test2, tokenizer, MAX_LEN)\n","\n","  training_loader = DataLoader(training_set, **train_params)\n","  testing_loader = DataLoader(testing_set, **test_params)\n","\n","  print(f\"Training fold {f}...\")\n","\n","  for epoch in range(0, EPOCHS):\n","    \n","    # Train\n","    train_acc, train_loss = train(model, epoch, training_loader)\n","    # Val\n","    val_acc, val_loss = valid(model, testing_loader)\n","    print(f\"Epoch {epoch+1} done!\")\n","    # Log metrics\n","    # wandb.log({\"Train_Loss\": train_loss, \"Val_Loss\": val_loss, \"Train_Acc\": train_acc, \"Val_Acc\": val_acc, \"Epoch\": epoch})   \n","\n","  # wandb.finish()\n","  f+=1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jUfUWS5-It4a"},"source":["### Save model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3340,"status":"ok","timestamp":1635441145015,"user":{"displayName":"Jun Xian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdSvjzNJuPRvBm68e_4yYL4N9PUSuGs-FMUyCBog=s64","userId":"17208504523579366933"},"user_tz":-480},"id":"X9PXHnI-IowG","outputId":"345d2844-5822-41a6-bbc4-7c63aec2c2cf"},"outputs":[{"data":{"text/plain":["('/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/bert_large2/vocab.txt',)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# Large model\n","bert_large = model\n","torch.save(bert_large, '/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/bert_large2/bert_sent_large.bin')\n","tokenizer.save_vocabulary('/content/drive/MyDrive/3.1/CZ4042 Neural Networks & Deep Learning/Project/emotion/models/bert_large2/')\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOzCaaw00hEVzNFlUFQo8RE","collapsed_sections":["OW9pCCPaQJa6","beCCkJ6DQBtf","0KgP7rRLQFZO","OuzN46oCQMOc","RJ9ZRe_4BGGf","Iz3SZaTNYQQM","Vl9Ax3Nw_BZn","uvMqzCKtTuEa","yJR_LDAQNjaR","6sBbhhzJiENf","uqUG7OGFgOOW","jUfUWS5-It4a"],"name":"BERT_large.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"025a2a0e3f6f4047889e7e02d8f20e4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0335994ccfab42a7b2dcc1ed8be87c85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58834e1349b54d06a5cd83737f90a1f4","IPY_MODEL_1d0290a2cb5e4187a0bb0f5669eb9e6e","IPY_MODEL_e81f9de618c54e85845e1c60e1d65ae3"],"layout":"IPY_MODEL_fd4ef819bc644ad787ffeba28cf8414e"}},"0406e3f6db304488875f229bc8b0040b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"099db3381ba1422f95fd774510dd3104":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a8eecc1f56c4b69b5672cd73b01fb79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6548e249cac849c8a492eca23209dae9","placeholder":"​","style":"IPY_MODEL_a672c0b1171e41afb3fb041002c9289f","value":"Downloading: 100%"}},"0f9d41b523774faaa3ee1e3608205dae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15d34fd248e047ec942422052c46c991":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"178f1efc53794c3180633ab708e72c37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c59b9bebcca48b0b9a255baf5580a11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d0290a2cb5e4187a0bb0f5669eb9e6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24667d2ed7714e429970713ce65d9926","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c59b9bebcca48b0b9a255baf5580a11","value":29}},"200a7bb9305348c9a80106df11f27ae0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bedacf9cd5574396b582366b87339d9b","IPY_MODEL_d37a851827ef40f0916d289b4024b33f","IPY_MODEL_ea1651d044314cf7830e210cb0445a6f"],"layout":"IPY_MODEL_44700002ab934fa7937debe909f09120"}},"24667d2ed7714e429970713ce65d9926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"255d3c230f7c401f8fd821b8f91b9f20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d7ff72b31fe438982898a2a0135af24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30ba4232670947e1a4d39813aeb405bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db02a3ea5a1d4a24af5d649367d73cc4","placeholder":"​","style":"IPY_MODEL_3edb60b9bfee41299b3286d3e165e847","value":" 208k/208k [00:00&lt;00:00, 2.30MB/s]"}},"32be20b70f47403482814aaa588ba6bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32de94e0f34c4dcdab4600d2bfffc19e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3edb60b9bfee41299b3286d3e165e847":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f560af2be2744b7924f431889f6bb43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6feeebc691104a64b768e9ee85438267","IPY_MODEL_75bbf1de3ec44c9f8f2676451b7e0986","IPY_MODEL_30ba4232670947e1a4d39813aeb405bf"],"layout":"IPY_MODEL_ba45b7fb19704369a8aa3dcb9709d3e7"}},"406e51c268c744d3bba7c6b4004269b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44700002ab934fa7937debe909f09120":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a5e18ffe8f54866822aca2745f3b243":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc0b31ef33ad4f3496a29fe7ea5315df","max":762,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d7ff72b31fe438982898a2a0135af24","value":762}},"50359db47c5f4fd9ba4ccdf378bdcac5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58834e1349b54d06a5cd83737f90a1f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_178f1efc53794c3180633ab708e72c37","placeholder":"​","style":"IPY_MODEL_935fcf0ba86744cd9c7f0b34f061985a","value":"Downloading: 100%"}},"61dd9147db3140b1b539718a6562ff63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6548e249cac849c8a492eca23209dae9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a317fe36dd8482a905feec7ea6cec82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6feeebc691104a64b768e9ee85438267":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15d34fd248e047ec942422052c46c991","placeholder":"​","style":"IPY_MODEL_406e51c268c744d3bba7c6b4004269b5","value":"Downloading: 100%"}},"75bbf1de3ec44c9f8f2676451b7e0986":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f9d41b523774faaa3ee1e3608205dae","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50359db47c5f4fd9ba4ccdf378bdcac5","value":213450}},"77db3fcb103c4466a7f19bd034e38a19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7a295763aa042f38004b05b610eb755","IPY_MODEL_b02a4876a3604e18be4bd80a07c1c3d2","IPY_MODEL_7e56aa9a0c9d4234be4d7e7f3f717b88"],"layout":"IPY_MODEL_98f18e989e3f46f6a7a6c38f56f11467"}},"7e56aa9a0c9d4234be4d7e7f3f717b88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb4f26aa0ce641c394b7aa687cb27086","placeholder":"​","style":"IPY_MODEL_aa1599d5149e45caa3001f6ff3742432","value":" 426k/426k [00:00&lt;00:00, 2.93MB/s]"}},"800cfd40a89644639a5fd2527ea834f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84b130932eaf49e1a745502a945efe08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"935fcf0ba86744cd9c7f0b34f061985a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98e0dc3b290042d7947e8093bb24e738":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98f18e989e3f46f6a7a6c38f56f11467":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a672c0b1171e41afb3fb041002c9289f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa1599d5149e45caa3001f6ff3742432":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab1d104f4c6b455b8817f225ef158adc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b02a4876a3604e18be4bd80a07c1c3d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84b130932eaf49e1a745502a945efe08","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a317fe36dd8482a905feec7ea6cec82","value":435797}},"b7a295763aa042f38004b05b610eb755":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea82d49fa4c244ab93f2caef2550dac7","placeholder":"​","style":"IPY_MODEL_32be20b70f47403482814aaa588ba6bf","value":"Downloading: 100%"}},"ba45b7fb19704369a8aa3dcb9709d3e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bedacf9cd5574396b582366b87339d9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_800cfd40a89644639a5fd2527ea834f3","placeholder":"​","style":"IPY_MODEL_255d3c230f7c401f8fd821b8f91b9f20","value":"Downloading: 100%"}},"cb4f26aa0ce641c394b7aa687cb27086":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d37a851827ef40f0916d289b4024b33f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_025a2a0e3f6f4047889e7e02d8f20e4f","max":1338740706,"min":0,"orientation":"horizontal","style":"IPY_MODEL_099db3381ba1422f95fd774510dd3104","value":1338740706}},"db02a3ea5a1d4a24af5d649367d73cc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e81f9de618c54e85845e1c60e1d65ae3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9e7eca1da414b2a9126fb0ec287912f","placeholder":"​","style":"IPY_MODEL_ee592576407d4cb0b28bf8015366f198","value":" 29.0/29.0 [00:00&lt;00:00, 924B/s]"}},"e9e7eca1da414b2a9126fb0ec287912f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea1651d044314cf7830e210cb0445a6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98e0dc3b290042d7947e8093bb24e738","placeholder":"​","style":"IPY_MODEL_32de94e0f34c4dcdab4600d2bfffc19e","value":" 1.25G/1.25G [00:31&lt;00:00, 50.6MB/s]"}},"ea82d49fa4c244ab93f2caef2550dac7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee592576407d4cb0b28bf8015366f198":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7169b627b384f83939bf64e23feda49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0406e3f6db304488875f229bc8b0040b","placeholder":"​","style":"IPY_MODEL_61dd9147db3140b1b539718a6562ff63","value":" 762/762 [00:00&lt;00:00, 22.1kB/s]"}},"fc0b31ef33ad4f3496a29fe7ea5315df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd4ef819bc644ad787ffeba28cf8414e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fddb3355d84e4aadada3367f6fb96fe6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a8eecc1f56c4b69b5672cd73b01fb79","IPY_MODEL_4a5e18ffe8f54866822aca2745f3b243","IPY_MODEL_f7169b627b384f83939bf64e23feda49"],"layout":"IPY_MODEL_ab1d104f4c6b455b8817f225ef158adc"}}}}},"nbformat":4,"nbformat_minor":0}
